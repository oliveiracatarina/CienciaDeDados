{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d29efa",
   "metadata": {},
   "source": [
    "# Regression, Classification, Decision Trees, and Ensemble Models\n",
    "\n",
    "\n",
    "## 1. Regressão\n",
    "\n",
    "Na regressão linear, a multicolinearidade entre as variáveis independentes pode desestabilizar os coeficientes do modelo. Explique como a **Regressão Ridge** e a **Regressão Lasso** abordam essa questão de maneiras diferentes. Em quais cenários você preferiria uma em vez da outra?\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Classificação\n",
    "\n",
    "Explique como o **desequilíbrio de classes** afeta o desempenho dos modelos de classificação. Quais estratégias você usaria para lidar com um conjunto de dados com uma variável alvo altamente desbalanceada, e como essas estratégias impactariam as métricas de avaliação do modelo?\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Árvores de Decisão\n",
    "\n",
    "Árvores de Decisão são conhecidas pela tendência de se ajustarem demais aos dados de treinamento. Descreva o papel da **poda de árvores** e do **hiperparâmetro de profundidade máxima** no controle do overfitting. Como essas técnicas equilibram viés e variância no modelo?\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Modelos de Ensemble\n",
    "\n",
    "Compare e contraste **Bagging** (por exemplo, Random Forest) e **Boosting** (por exemplo, Gradient Boosting Machines) em termos de suas abordagens para reduzir variância e viés. Como cada método afeta a robustez e interpretabilidade do modelo final?\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Conjuntos de Árvores para Regressão vs Classificação\n",
    "\n",
    "Métodos de ensemble baseados em árvores, como Random Forests e Gradient Boosting, podem ser usados tanto para regressão quanto para classificação. Descreva as principais diferenças em como esses algoritmos são configurados e avaliados para problemas de regressão e classificação. Como os critérios de divisão e as métricas de desempenho mudam entre esses contextos?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb2f8b",
   "metadata": {},
   "source": [
    "# Respostas das questões\n",
    "# Questão 1\n",
    "Regressão Ridge e Regressão Lasso são técnicas de regularização, que abordam a questão da multicolinearidade e reduzem o impacto de variáveis altamente correlacionadas entre si, mas de formas diferentes:\n",
    "\n",
    "- Regressão Ridge: adiciona uma penalidade proporcional ao quadrado da magnitude dos coeficientes. Essa penalidade força os coeficientes a reduzirem em direção a zero, mas nunca zera completamente.\n",
    "\n",
    "- Regressão Lasso: adiciona uma penalidade proporcional ao valor absoluto dos coeficientes. Diferente da Regressão de Ridge, alguns coeficientes podem ser forçados a serem exatamente zero, resultando em seleção de variáveis.\n",
    "\n",
    "Cenários para preferir Regressão Ridge: quando todas as variáveis contribuem para o modelo e é desejado apenas a magnitude dos coeficientes.\n",
    "Cenários para preferir Regressão Lasso: quando é necessária a seleção automática de variáveis, eliminando características irrelevantes.\n",
    "\n",
    "# Questão 2\n",
    "O desiquilíbrio de classes ocorre quando a quantidade de informações de uma classe é muito maior que a outra. Isso impacta no desempenho dos modelos de classficação de diversas formas, como no viés do modelo (onde o algoritmo tende a focar na classe majoritária) e em métricas enganosas.\n",
    "\n",
    "Algumas estratégias para lidar com isso são:\n",
    "- Reamostragem dos dados:\n",
    "    - Oversampling: que consiste em aumentar os exemplos da classe minoritária, podendo ser feito de forma simples (duplicando exemplos) ou usando técnicas como **SMOTE (Synthetic Minority Over-sampling Technique)**, que gera exemplos sintéticos;\n",
    "    - Undersampling: que reduz exemplos da classe majoritária.\n",
    "- Ponderação de classes: uso de pesos diferentes atribuídos às classes durante o treinamento (sklearn), penalizando mais os erros na classe menor.\n",
    "- Troca de métricas para avaliação: \n",
    "    - F1-Score: média harmônica entre precisão (saber quantos dos positivos previstos eram realmente positivos) e recall (quantos positivos reais foram identificados corretamente);\n",
    "    - ROC-AUC (Receiver Operating Characteristic - Area Under the Curve): mede a capacidade do modelo de distinguir entre positivos e negativos em diferentes limiares e são menos sensíveis ao desequilíbrio.\n",
    "        - ROC: curva que plota a taxa de verdadeiros positivos vs taxa de falsos positivos;\n",
    "        - AUC: área sob a curva. Quanto maior o valor (próximo de 1), melhor a separação entre as classes.\n",
    "\n",
    "O objetivo ao lidar com o desequilíbro é melhorar o desempenho da classe minoritária, mesmo que signifique uma redução na acurácia geral, resultando em um modelo mais útil e robusto.\n",
    "\n",
    "# Questão 3\n",
    "Árvores de Decisão são propensas ao overfitting, pois podem se ajustar excessivamente aos dados de treinamento, capturando ruído e padrões específicos da amostra, o que compromete a generalização para novos dados. Para combater isso:\n",
    "- Poda de árvores: remove nós irrelevantes ou de baixa importância  para simplificar a árvore e melhorar generalização;\n",
    "- Hiperparâmetro de profundidade máxima: define um limite para a qtde de divisões. Uma árvore muito profunda pode capturar ruído em vez de padrões reais.\n",
    "\n",
    "São técnicas de regularização para árvores de decisão, essenciais para equilibrar o viés e a variância, buscando um modelo que seja complexo o suficiente para capturar os padrões subjacentes (baixo viés) sem se ajustar ao ruído (baixa variância), garantindo assim uma boa generalização.\n",
    "\n",
    "# Questão 4\n",
    "Modelos de ensemble combinam múltiplas previsões de modelos base para melhorar o desempenho. Bagging e Boosting são as duas principais abordagens, com diferenças fundamentais na redução de viés e variância.\n",
    "- Bagging (bootstrap aggregating): vários modelos são treinados em subconjuntos aleatórios dos dados, reduz a variância (evitando o overfitting) e o resultado é obtido por média - para regressão - ou voto majoritário - para classificação -, além de ser mais robusto e fácil de paralelizar.\n",
    "- Boosting: modelos treinados sequencialmente (que corrigem erros dos modelos anteriores), reduz viés (tornando a previsão mais precisa), são mais sensíveis a ruidos, entretanto, tem alto desempenho.\n",
    "\n",
    "Exemplos práticos incluem o Random Forest para Bagging e o AdaBoost, Gradient Boosting ou XGBoost para Boosting. Bagging tende a ser mais robusto a outliers e ruídos, enquanto Boosting pode ser mais sensível, exigindo técnicas de regularização para evitar overfitting. Ambos os métodos, ao combinar várias árvores, sacrificam a interpretabilidade em troca de maior desempenho preditivo.\n",
    "\n",
    "# Questão 5\n",
    "Métodos de ensemble baseados em árvore, como Random Forests e Gradiente Boosting, são aplicáveis tanto para problemas de regressão (previsão de valores contínuos) quanto de classificação (previsão de categorias). As principais diferenças residem na configuração do algoritmo, nos critérios de divisão das árvores e nas métricas de avaliação.\n",
    "- Configuração do algoritmo:\n",
    "    - Classificação: As árvores são configuradas para prever classes categóricas. Cada nó tenta dividir os dados de forma a maximizar a pureza das classes nos subconjuntos.\n",
    "    - Regressão: As árvores são ajustadas para prever valores contínuos. Os nós são divididos para minimizar o erro na previsão dos valores numéricos.\n",
    "\n",
    "- Critérios de divisão das árvores:\n",
    "    - Classificação: Gini Impurity (Impureza de Gini). Entropy (Entropia ou Ganho de Informação). O objetivo é criar nós que sejam os mais homogêneos possíveis em relação às classes.\n",
    "    - Regressão: Minimização do Erro Quadrático Médio (MSE) ou Erro Absoluto Médio (MAE). As divisões buscam minimizar a variância dos valores contínuos nos nós filhos.\n",
    "\n",
    "- Métricas de desempenho:\n",
    "    - Classificação: Avalia a precisão na previsão das classes com métricas, como acurácia, precisão, recall, F1-scre, matriz de confusão e ROC-AUC.\n",
    "    - Regressão: Avalia o quão próximo dos valores reais o modelo chega,usando métricas como: erro quadrático médio (MSE), raiz do erro quadrático médio (RMSE), erro absoluto médio (MAE), R² (coeficiente de determinação).\n",
    "\n",
    "Portanto, embora a estrutura dos algoritmos seja a mesma, a forma como eles dividem os dados e avaliam a performance muda significativamente, dependendo se o problema é de regressão ou classificação.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
